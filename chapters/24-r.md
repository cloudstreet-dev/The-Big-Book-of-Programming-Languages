# Chapter 24: R - Statistics, Visualizations, and Mysterious Syntax

## The Statistician's Language

R was created in 1993 by Ross Ihaka and Robert Gentleman at the University of Auckland as an open-source implementation of S (a statistical language from Bell Labs). The name "R" comes from the first names of its creators and is a play on "S."

R wasn't designed for general-purpose programming. It was designed for statisticians, by statisticians, to do statistics. The syntax shows it—R has quirks that puzzle programmers but feel natural to people who think in statistical terms.

By 2025, R is the language of academic statistics, data analysis, and data visualization. It's especially strong in bioinformatics, social sciences, and anywhere sophisticated statistical methods matter more than software engineering purity.

## The Philosophy

R's design principles:

**Interactive analysis**: REPL-first. Explore data interactively.

**Statistical computing**: Built-in statistical functions and data structures.

**Vectorization**: Operations on entire vectors, not loops.

**Graphics**: Exceptional plotting and visualization capabilities.

**Extensibility**: Packages (over 19,000 on CRAN) extend functionality.

**Functional programming**: Functions are first-class values.

The result is a language optimized for data analysis, not software development.

## What It Looks Like

```r
# Simple expressions
x <- 42  # Assignment (use <- not =)
y = 42   # = also works but <- is preferred

# Vectors (fundamental data structure)
numbers <- c(1, 2, 3, 4, 5)

# Vectorized operations
doubled <- numbers * 2  # c(2, 4, 6, 8, 10)
evens <- numbers[numbers %% 2 == 0]  # c(2, 4)

# Functions
greet <- function(name) {
  paste("Hello,", name, "!")
}

greet("Alice")  # "Hello, Alice !"

# Data frames (like tables)
df <- data.frame(
  name = c("Alice", "Bob", "Charlie"),
  age = c(30, 25, 35),
  score = c(85, 90, 88)
)

# Accessing columns
df$name          # c("Alice", "Bob", "Charlie")
df[["age"]]      # c(30, 25, 35)
df[, "score"]    # c(85, 90, 88)

# Filtering
df[df$age > 26, ]  # Rows where age > 26

# Statistical functions
mean(df$age)     # 30
median(df$score) # 88
sd(df$score)     # Standard deviation

# Linear regression
model <- lm(score ~ age, data = df)
summary(model)

# Plotting
plot(df$age, df$score)

# With ggplot2 (popular package)
library(ggplot2)

ggplot(df, aes(x = age, y = score)) +
  geom_point() +
  geom_smooth(method = "lm")

# Pipe operator (with magrittr or tidyverse)
library(dplyr)

df %>%
  filter(age > 26) %>%
  select(name, score) %>%
  arrange(desc(score))
```

Key features:
- **Vectorization**: Operations on entire vectors
- **`<-` assignment**: Traditional R style
- **Data frames**: Central data structure
- **Statistical functions**: Built-in
- **Package ecosystem**: Massive (CRAN)

## The Type System

R is dynamically typed with a unique type system:

```r
# Basic types
x <- 42         # numeric (double)
y <- 42L        # integer (note the L)
s <- "hello"    # character
b <- TRUE       # logical

# Checking types
typeof(x)       # "double"
class(x)        # "numeric"

# Vectors (all elements same type)
numbers <- c(1, 2, 3)           # numeric vector
strings <- c("a", "b", "c")     # character vector
logicals <- c(TRUE, FALSE, TRUE)  # logical vector

# Type coercion (automatic)
mixed <- c(1, 2, "three")  # c("1", "2", "three") - all become characters

# Lists (different types allowed)
my_list <- list(
  number = 42,
  text = "hello",
  vector = c(1, 2, 3)
)

my_list$number   # 42
my_list[[2]]     # "hello"

# Data frames (list of equal-length vectors)
df <- data.frame(
  x = 1:3,
  y = c("a", "b", "c"),
  z = c(TRUE, FALSE, TRUE)
)

# Factors (categorical data)
colors <- factor(c("red", "blue", "red", "green"))
levels(colors)  # "blue" "green" "red"

# NULL and NA
x <- NULL       # Absence of a value
y <- NA         # Missing value (different!)

# Special values
Inf             # Infinity
-Inf            # Negative infinity
NaN             # Not a Number
```

The type system can surprise programmers from other languages.

## Vectorization: The R Way

R is built around vectors:

```r
# Bad (slow): loop
sum <- 0
for (i in 1:1000000) {
  sum <- sum + i
}

# Good (fast): vectorized
sum(1:1000000)

# Vectorized operations
x <- c(1, 2, 3, 4, 5)
y <- c(10, 20, 30, 40, 50)

# Element-wise operations
x + y       # c(11, 22, 33, 44, 55)
x * y       # c(10, 40, 90, 160, 250)
x > 3       # c(FALSE, FALSE, FALSE, TRUE, TRUE)

# Vector recycling (automatic)
x + 10      # c(11, 12, 13, 14, 15) - 10 is recycled
c(1, 2, 3) + c(10, 20)  # c(11, 22, 13) - recycling with warning

# Apply functions to vectors
sqrt(x)     # c(1.00, 1.41, 1.73, 2.00, 2.24)
log(x)      # Natural log of each element

# Filtering vectors
x[x > 2]    # c(3, 4, 5)
x[x %% 2 == 0]  # c(2, 4)

# Which() function
which(x > 3)  # c(4, 5) - indices
```

Vectorized code is idiomatic and fast in R.

## The Tidyverse: Modern R

The tidyverse is a collection of packages that modernize R:

```r
library(tidyverse)  # Loads dplyr, ggplot2, tidyr, etc.

# dplyr for data manipulation
df %>%
  filter(age > 25) %>%
  mutate(age_plus_10 = age + 10) %>%
  select(name, age_plus_10) %>%
  arrange(desc(age_plus_10))

# Common dplyr verbs:
# - filter(): filter rows
# - select(): select columns
# - mutate(): create new columns
# - arrange(): sort rows
# - summarize(): aggregate data
# - group_by(): group for aggregation

# Grouping and summarizing
df %>%
  group_by(category) %>%
  summarize(
    mean_score = mean(score),
    count = n()
  )

# ggplot2 for visualization
ggplot(df, aes(x = age, y = score)) +
  geom_point(aes(color = name), size = 3) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Age vs Score",
    x = "Age (years)",
    y = "Score"
  ) +
  theme_minimal()

# tidyr for reshaping data
# pivot_longer(), pivot_wider(), etc.
```

The tidyverse makes R more consistent and beginner-friendly.

## Statistical Modeling

R excels at statistical modeling:

```r
# Linear regression
model <- lm(y ~ x, data = df)
summary(model)

# Multiple regression
model <- lm(y ~ x1 + x2 + x3, data = df)

# Logistic regression
model <- glm(binary_outcome ~ predictor,
             data = df,
             family = binomial)

# ANOVA
model <- aov(score ~ group, data = df)

# T-test
t.test(group1, group2)

# Chi-squared test
chisq.test(table(df$category1, df$category2))

# Time series
ts_data <- ts(data, start = c(2020, 1), frequency = 12)
decompose(ts_data)

# Machine learning (with caret)
library(caret)

model <- train(
  outcome ~ .,
  data = df,
  method = "rf",  # Random forest
  trControl = trainControl(method = "cv", number = 10)
)
```

R has comprehensive statistical capabilities built-in.

## Graphics: R's Strength

R's plotting is world-class:

```r
# Base R plotting
plot(x, y)
hist(data)
boxplot(score ~ group, data = df)
barplot(counts)

# ggplot2 (grammar of graphics)
ggplot(data, aes(x = x_var, y = y_var)) +
  geom_point() +
  geom_line() +
  facet_wrap(~ category) +
  theme_bw()

# Many geoms available:
# geom_point(), geom_line(), geom_bar(),
# geom_histogram(), geom_boxplot(), geom_violin(),
# geom_density(), geom_smooth(), etc.

# Customization
ggplot(df, aes(x = age, y = score, color = group)) +
  geom_point(size = 3, alpha = 0.7) +
  scale_color_manual(values = c("red", "blue", "green")) +
  labs(
    title = "Relationship between Age and Score",
    subtitle = "Grouped by category",
    x = "Age (years)",
    y = "Score (points)",
    color = "Group"
  ) +
  theme_classic() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title = element_text(size = 12)
  )

# Interactive plots (with plotly)
library(plotly)
plot_ly(df, x = ~age, y = ~score, type = "scatter", mode = "markers")
```

Publication-quality graphics are R's specialty.

## What R Is Best For

**Statistical analysis**: Designed for this. Best in class.

**Data visualization**: ggplot2 is excellent.

**Bioinformatics**: Bioconductor packages dominate.

**Academic research**: Standard in many fields.

**Exploratory data analysis**: Interactive, flexible.

**Reporting**: R Markdown creates reports mixing code and text.

## What R Is Worst For

**General-purpose programming**: Not designed for this.

**Web applications**: Shiny exists but is niche. Use Python/JavaScript.

**Mobile apps**: Not applicable. Use Swift or Kotlin.

**Systems programming**: Wrong tool. Use C or Rust.

**Production software engineering**: R code often doesn't scale. Use Python for ML in production.

## The Ecosystem

**Package repository**: CRAN (Comprehensive R Archive Network) - 19,000+ packages

**Popular packages**:
- **Tidyverse**: dplyr, ggplot2, tidyr, readr, purrr
- **Bioconductor**: Bioinformatics packages
- **caret**: Machine learning
- **data.table**: Fast data manipulation
- **Shiny**: Web applications
- **knitr/rmarkdown**: Reproducible reports

**IDEs**: RStudio (the standard), VS Code (with R extension)

**Jupyter**: R kernels available for Jupyter notebooks

## The Quirks

R has unique syntax that confuses programmers:

```r
# Assignment <- vs =
x <- 42  # Preferred
x = 42   # Works but not idiomatic

# 1-indexed (not 0-indexed!)
numbers <- c(10, 20, 30)
numbers[1]  # 10 (not 20!)

# Negative indices remove elements
numbers[-1]  # c(20, 30) - removes first element

# Vector recycling
c(1, 2, 3) + c(10, 20)  # c(11, 22, 13) - surprising!

# Everything is a vector
42          # Actually a vector of length 1
"hello"     # Vector of length 1

# . is just a character in names
my.variable <- 42  # Totally fine, no method call

# Factors are integers underneath
f <- factor(c("low", "medium", "high"))
as.integer(f)  # c(2, 3, 1) - alphabetical order!

# NA vs NULL
x <- c(1, NA, 3)  # NA is a missing value in a vector
x <- NULL         # NULL is absence of object
```

These quirks make sense in statistical context but confuse software engineers.

## R vs Python for Data Science

The eternal debate:

**R**:
- Better for pure statistics
- Better visualizations (ggplot2)
- Designed for interactive analysis
- Tidyverse is coherent and elegant
- Stronger in bioinformatics

**Python**:
- Better for general programming
- Better for production ML (TensorFlow, PyTorch)
- More versatile (not just data)
- Larger overall ecosystem
- Better for software engineering

**The verdict**: Use R for statistics and exploration. Use Python for production ML and engineering.

## The Community

**The Academics**: Researchers, professors, statisticians. R's core users.

**The Data Scientists**: Use R for exploration, sometimes Python for production.

**The Bioinformaticians**: Bioconductor is essential for genomics.

**The Tidyverse Advocates**: Love dplyr and ggplot2. Hadley Wickham is their hero.

**The Base R Purists**: Don't need tidyverse. Base R is enough.

### Common Phrases
- "Just use ggplot2"
- "Have you tried the tidyverse?"
- "This is all vectorized"
- "CRAN has a package for that"
- "R vs Python? Both!" (diplomatic answer)
- "It's in the paper's supplementary materials"

## R Markdown: Reproducible Research

R Markdown mixes code and text:

```r
---
title: "My Analysis"
author: "Data Scientist"
output: html_document
---

## Introduction

This is my analysis of the data.

```{r}
# Load data
df <- read.csv("data.csv")

# Summary statistics
summary(df)
```

## Visualization

```{r, echo=FALSE, fig.width=8, fig.height=6}
library(ggplot2)
ggplot(df, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth()
```

The correlation is `r cor(df$x, df$y)`.
```

R Markdown creates reports, papers, presentations, and websites.

## Should You Learn R?

**Yes, if**:
- You're doing academic research in statistics
- You work in bioinformatics or genomics
- You need advanced statistical methods
- You value visualization quality
- You're in a field where R is standard

**No, if**:
- You're doing general software development
- You need production ML (use Python)
- You're building web or mobile apps
- You prefer traditional programming languages

**Maybe, if**:
- You're a data scientist (know both R and Python)
- You want to create beautiful visualizations
- You're exploring data science as a field

## The Verdict

R is the statistician's language. It wasn't designed for software engineering—it was designed for exploring data, running statistical tests, and creating visualizations. At these tasks, it excels.

The syntax is quirky. The 1-indexing confuses programmers. The automatic type coercion causes bugs. But for statisticians, R feels natural. The vectorization is elegant. The statistical functions are comprehensive. The visualization capabilities are unmatched.

In 2025, R isn't as trendy as Python in the data science world. Python has won for production ML. But R remains dominant in academic statistics, bioinformatics, and fields where statistical rigor matters more than software engineering practices.

If you're going into academic research, learning R is essential. If you're a data scientist, knowing both R and Python makes you versatile. If you're a software engineer who occasionally analyzes data, Python might be enough.

R proves that a language can succeed by being the best tool for a specific domain, even if it's not great for general purposes. It's the right tool for the right job—and that job is statistics.

Learn R for the statistics. Tolerate the quirks. Appreciate ggplot2. Create beautiful visualizations. Publish reproducible research. R might not be elegant software engineering, but it's elegant statistical computing.

---

**Next**: [Chapter 25: Julia - Python's Speed-Obsessed Cousin](25-julia.md)
